# A1 - TESTE 

## üìò Banco de Quest√µes ‚Äì Minera√ß√£o de Dados (Prova Escrita)
### üìò Gabarito ‚Äì Banco de Quest√µes Minera√ß√£o de Dados

## Parte 1 ‚Äì Quest√µes Objetivas

1. **b)** Dois ramos, representando uma condi√ß√£o l√≥gica de separa√ß√£o.
   ‚Üí Em √°rvores bin√°rias cada teste divide o conjunto em 2.

2. **d)** Todas as alternativas est√£o corretas.
   ‚Üí O √≠ndice de Gini mede pureza, menor valor indica mais pureza e √© usado no CART.

3. **Verdadeiro ou Falso:**

   * (F) Pr√©-poda consiste em **parar cedo**, n√£o em cortar depois.
   * (V) P√≥s-poda remove ramos fracos **ap√≥s** construir a √°rvore completa.

4. **a)** Treino, teste e valida√ß√£o.

5. **b)** Precis√£o, recall e F1-score.
   ‚Üí S√£o mais adequadas em bases desbalanceadas que a acur√°cia.

6. **b)** Defini√ß√£o do problema ‚Üí Pr√©-processamento ‚Üí Transforma√ß√£o ‚Üí Treinamento ‚Üí Avalia√ß√£o ‚Üí Interpreta√ß√£o.

---

## Parte 2 ‚Äì Quest√µes Subjetivas

7. **Classifica√ß√£o supervisionada x Clustering:**

   * Classifica√ß√£o supervisionada: usa **dados rotulados** para aprender regras e prever classes futuras.
   * Clustering: √© **n√£o supervisionado**, agrupa dados semelhantes sem r√≥tulos pr√©vios.

8. **Pr√©-processamento:**

   * Importante para garantir qualidade do modelo.
   * Exemplos:

     * Tratar valores faltantes (ex.: substituir m√©dias em atributos num√©ricos).
     * Normalizar vari√°veis para que fiquem na mesma escala.

9. **Pr√©-poda x P√≥s-poda:**

   * Pr√©-poda: impede crescimento excessivo (profundidade m√°xima, m√≠nimo de registros por n√≥). Evita overfitting, mas pode parar cedo demais.
   * P√≥s-poda: cresce a √°rvore inteira e depois corta ramos de pouca relev√¢ncia. Melhora generaliza√ß√£o, mas √© mais custoso.

10. **Interpreta√ß√£o da √°rvore (cr√©dito):**

* Primeiro crit√©rio √© renda: indica que a vari√°vel renda √© mais determinante para aprova√ß√£o.
* Depois tempo de emprego: mostra que estabilidade profissional tamb√©m influencia.
* A √°rvore traduz a **l√≥gica do neg√≥cio** em regras claras.

11. **F1-score:**

* F√≥rmula: 2¬∑(Precis√£o¬∑Recall)/(Precis√£o+Recall).
* Prefer√≠vel quando as classes est√£o desbalanceadas, pois equilibra precis√£o e recall, diferente da acur√°cia que pode enganar.

12. **ROC/AUC:**

* Curva ROC: mostra trade-off entre sensibilidade (TPR) e taxa de falsos positivos (FPR).
* AUC: √°rea sob a curva, mede poder discriminativo.
* AUC ‚âà 0,5: modelo n√£o √© melhor que um chute aleat√≥rio.

13. **Valida√ß√£o cruzada (k-fold):**

* Divide o dataset em k partes. Cada parte √© usada uma vez como teste e k-1 vezes como treino.
* Estratificada: garante que a propor√ß√£o de classes seja mantida em cada fold, evitando distor√ß√µes.

14. **Engenharia de atributos:**

* Inclui transforma√ß√µes como:

  * Codifica√ß√£o de categ√≥ricas (ex.: One-Hot).
  * Normaliza√ß√£o (Min-Max, Z-score).
  * Cria√ß√£o de novas vari√°veis derivadas.
* Visa melhorar a capacidade preditiva do modelo.

15. **Matriz de confus√£o:**

* Representa acertos e erros do modelo em cada classe.
* Exemplo: ajuda a ver se h√° muitos falsos negativos (ex.: fraude classificada como normal), o que √© cr√≠tico em aplica√ß√µes de seguran√ßa.

---

## Parte 3 ‚Äì Interpreta√ß√£o de Resultados

16. **Acur√°cia 95% e Recall 50%:**

* Modelo acerta muito no geral, mas falha em detectar a classe positiva (s√≥ encontra metade dos casos).
* Indica problema em base desbalanceada ou foco em acertos da classe majorit√°ria.

17. **De 100 folhas para 15 folhas:**

* Foi aplicada **poda** (provavelmente p√≥s-poda com cost-complexity).
* Impacto: modelo menos complexo, mais generaliz√°vel, menor risco de overfitting.

18. **Alto treino, baixo teste:**

* Problema de **overfitting** (modelo memorizou o treino).
* Medidas:

  * Poda (no caso de √°rvores).
  * Regulariza√ß√£o ou ajuste de hiperpar√¢metros.
  * Mais dados ou valida√ß√£o cruzada.

---
---

