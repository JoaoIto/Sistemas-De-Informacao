{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e1dd75-90f3-4451-98ad-f3341578b106",
   "metadata": {},
   "source": [
    "# <center> SISTEMAS DE INFORMAÇÃO</center>\n",
    "### <center> MINERAÇÃO DE DADOS</center>\n",
    "### <center> ATIVIDADE - AULA 04 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596c5a9-93a7-46f8-aa0d-48bb7886022e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46601ea9",
   "metadata": {},
   "source": [
    "# Gerador de Dataset Sintético **sujo** \n",
    "\n",
    "Este notebook cria datasets sintéticos com **inconsistências aleatórias** a cada execução:\n",
    "- valores ausentes\n",
    "- grafia errada (ruído textual)\n",
    "- idades inconsistentes\n",
    "- datas inconsistentes\n",
    "- situações que exigem **imputação numérica** e **imputação categórica**\n",
    "- registros duplicados\n",
    "\n",
    "No final, salva um CSV com **timestamp** (para não sobrescrever) e imprime um **relatório** das sujeiras inseridas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478fb308-a467-4f0e-98b5-fc66a5e2ef27",
   "metadata": {},
   "source": [
    "## Atividade\n",
    "A atividade dessa aula consiste em gerar um um dataset \"sujo\", ou seja, com inconsistências e em seguida realizar o seu pré-processamento\n",
    "Vocês deverão enviar o notebook com os passos executados para realizar o limpeza do dataset\n",
    "O notebook deverá ter uma célula com um texto explicativo antes da execução de alguma tarefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf9262",
   "metadata": {},
   "source": [
    "## (Opcional) Montar o Google Drive\n",
    "Execute esta célula se quiser salvar a saída direto no seu Drive. Se não precisar, **pule** e a saída ficará no diretório atual (`/content`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053b9d5",
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "USE_DRIVE = False  # Altere para True para salvar no Drive\n",
    "OUTPUT_DIR = \"/content\"  # Pasta padrão quando USE_DRIVE=False\n",
    "\n",
    "if USE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Ajuste o caminho abaixo para sua pasta no Drive (ex.: 'MyDrive/datasets')\n",
    "    OUTPUT_DIR = \"/content/drive/MyDrive/datasets\"\n",
    "\n",
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Salvar arquivos em: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f6298",
   "metadata": {},
   "source": [
    "## Parâmetros do gerador\n",
    "- Defina `SEMENTE` como um inteiro para reprodutibilidade.\n",
    "- Deixe `SEMENTE=None` para aleatoriedade total a cada execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee6105",
   "metadata": {
    "id": "params"
   },
   "outputs": [],
   "source": [
    "import numpy as np, random\n",
    "\n",
    "N = 10_000          # número de linhas\n",
    "SEMENTE = None      # use um inteiro (ex.: 42) para resultados reprodutíveis\n",
    "\n",
    "if SEMENTE is not None:\n",
    "    np.random.seed(SEMENTE)\n",
    "    random.seed(SEMENTE)\n",
    "\n",
    "print(f\"N linhas = {N} | Semente = {SEMENTE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4cd346",
   "metadata": {},
   "source": [
    "## Gerar dataset e injetar inconsistências\n",
    "A execução cria o DataFrame base (limpo) e então aplica **sujeiras** em porções aleatórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0759303",
   "metadata": {
    "id": "generator"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Catálogos simples\n",
    "NOMES = [\n",
    "    \"Ana\",\"Bruno\",\"Carla\",\"Diego\",\"Eva\",\"Fabio\",\"Gabriela\",\"Heitor\",\"Iris\",\"Joao\",\n",
    "    \"Karina\",\"Lucas\",\"Mariana\",\"Nicolas\",\"Olivia\",\"Paulo\",\"Rita\",\"Saulo\",\"Tania\",\"Ulisses\",\n",
    "    \"Vera\",\"Will\",\"Xavier\",\"Yasmin\",\"Zeca\"\n",
    "]\n",
    "SOBRENOMES = [\"Silva\",\"Santos\",\"Oliveira\",\"Souza\",\"Lima\",\"Pereira\",\"Almeida\",\"Ferreira\",\"Rodrigues\",\"Carvalho\"]\n",
    "CIDADES = [\"sao paulo\",\"rio de janeiro\",\"belo horizonte\",\"curitiba\",\"recife\",\"salvador\",\"manaus\",\"fortaleza\",\"goiania\",\"belem\"]\n",
    "CARGOS = [\"analista\",\"cientista de dados\",\"engenheiro de dados\",\"desenvolvedor\",\"estagiario\",\"gestor\"]\n",
    "ESTADOS_CIVIS = [\"solteiro\",\"casado\",\"divorciado\",\"viuvo\"]\n",
    "\n",
    "def nome_completo():\n",
    "    return f\"{random.choice(NOMES)} {random.choice(SOBRENOMES)}\"\n",
    "\n",
    "def data_aleatoria(inicio=datetime(2015,1,1), fim=datetime(2025,8,1)):\n",
    "    delta = fim - inicio\n",
    "    return inicio + timedelta(days=random.randint(0, delta.days))\n",
    "\n",
    "# 1) Base limpa\n",
    "idades = np.clip(np.random.normal(35, 10, N).round().astype(int), 14, 90)\n",
    "salarios = np.random.lognormal(mean=8.0, sigma=0.45, size=N).round(2)\n",
    "datas = [data_aleatoria().strftime(\"%d/%m/%Y\") for _ in range(N)]\n",
    "telefones = [f\"(11) 9{random.randint(1000,9999)}-{random.randint(1000,9999)}\" for _ in range(N)]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'nome': [nome_completo() for _ in range(N)],\n",
    "    'idade': idades,\n",
    "    'cidade': np.random.choice(CIDADES, N),\n",
    "    'data_admissao': datas,\n",
    "    'salario': salarios,\n",
    "    'estado_civil': np.random.choice(ESTADOS_CIVIS, N),\n",
    "    'cargo': np.random.choice(CARGOS, N),\n",
    "    'telefone': telefones\n",
    "})\n",
    "\n",
    "# 2) Inconsistências aleatórias\n",
    "summary = {}\n",
    "\n",
    "# 2.1 Ausentes\n",
    "proporcoes_na = {\n",
    "    'idade': np.random.uniform(0.02, 0.08),\n",
    "    'salario': np.random.uniform(0.02, 0.08),\n",
    "    'cidade': np.random.uniform(0.02, 0.08),\n",
    "    'estado_civil': np.random.uniform(0.01, 0.06),\n",
    "    'cargo': np.random.uniform(0.01, 0.05),\n",
    "    'telefone': np.random.uniform(0.60, 0.95)\n",
    "}\n",
    "for col, p in proporcoes_na.items():\n",
    "    m = np.random.rand(N) < p\n",
    "    df.loc[m, col] = np.nan\n",
    "summary['na_inseridos_est'] = {k: round(v*N) for k, v in proporcoes_na.items()}\n",
    "\n",
    "# 2.2 Grafia errada (ruído textual)\n",
    "def ruidificar_texto(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    s2 = s\n",
    "    if random.random() < 0.5:\n",
    "        s2 = f\"  {s2}  \"\n",
    "    if random.random() < 0.5:\n",
    "        s2 = s2.upper() if random.random() < 0.5 else s2.title()\n",
    "    mapa = {\"o\":\"0\",\"i\":\"1\",\"e\":\"3\",\"a\":\"4\"}\n",
    "    if random.random() < 0.4:\n",
    "        for k,v in mapa.items():\n",
    "            if random.random() < 0.3:\n",
    "                s2 = s2.replace(k, v)\n",
    "    if random.random() < 0.5:\n",
    "        s2 = s2.replace(\" \", \"  \")\n",
    "    return s2\n",
    "\n",
    "for col in ['nome','cidade','estado_civil','cargo']:\n",
    "    mask_ruido = np.random.rand(N) < np.random.uniform(0.05, 0.15)\n",
    "    df.loc[mask_ruido, col] = df.loc[mask_ruido, col].astype('object').apply(ruidificar_texto)\n",
    "summary['ruido_texto_cols'] = ['nome','cidade','estado_civil','cargo']\n",
    "\n",
    "# 2.3 Idades inconsistentes\n",
    "idx_bad_idade = np.random.choice(df.index, size=int(np.random.uniform(0.01, 0.03)*N), replace=False)\n",
    "choices = [-5, -1, 5, 8, 10, 120, 150]\n",
    "df.loc[idx_bad_idade, 'idade'] = np.random.choice(choices, size=len(idx_bad_idade))\n",
    "summary['idades_inconsistentes'] = int(len(idx_bad_idade))\n",
    "\n",
    "# 2.4 Datas inconsistentes (futuras ou lixo)\n",
    "def data_futura():\n",
    "    base = datetime(2027,1,1)\n",
    "    return (base + timedelta(days=random.randint(0, 365*3))).strftime('%d/%m/%Y')\n",
    "idx_bad_data = np.random.choice(df.index, size=int(np.random.uniform(0.01, 0.03)*N), replace=False)\n",
    "for i in idx_bad_data:\n",
    "    df.at[i, 'data_admissao'] = data_futura() if random.random() < 0.7 else 'xx/yy/zzzz'\n",
    "summary['datas_inconsistentes'] = int(len(idx_bad_data))\n",
    "\n",
    "# 2.5 Outliers/negativos em salário\n",
    "sal = pd.to_numeric(df['salario'], errors='coerce')\n",
    "idx_ruido_sal = np.random.choice(df.index, size=int(np.random.uniform(0.01, 0.03)*N), replace=False)\n",
    "mult = np.random.choice([10, 20, 0.05], size=len(idx_ruido_sal))\n",
    "sal.loc[idx_ruido_sal] = sal.loc[idx_ruido_sal] * mult\n",
    "neg_idx = np.random.choice(df.index, size=int(np.random.uniform(0.003, 0.01)*N), replace=False)\n",
    "sal.loc[neg_idx] = -abs(sal.loc[neg_idx].fillna(1000))\n",
    "df['salario'] = sal\n",
    "summary['salarios_ruido'] = int(len(idx_ruido_sal))\n",
    "summary['salarios_negativos'] = int(len(neg_idx))\n",
    "\n",
    "# 2.6 Duplicatas\n",
    "dup_frac = np.random.uniform(0.01, 0.03)\n",
    "dups = df.sample(frac=dup_frac, replace=False, random_state=None)\n",
    "df_sujo = pd.concat([df, dups], ignore_index=True).sample(frac=1.0, random_state=None).reset_index(drop=True)\n",
    "summary['duplicatas_inseridas'] = int(len(dups))\n",
    "\n",
    "# 3) Conversões de tipo para facilitar a limpeza\n",
    "df_sujo['data_admissao'] = pd.to_datetime(df_sujo['data_admissao'], format='%d/%m/%Y', errors='coerce')\n",
    "df_sujo['idade'] = pd.to_numeric(df_sujo['idade'], errors='coerce')\n",
    "df_sujo['salario'] = pd.to_numeric(df_sujo['salario'], errors='coerce')\n",
    "\n",
    "# 4) Relatório rápido\n",
    "relatorio = {\n",
    "    'linhas_geradas_total': int(len(df_sujo)),\n",
    "    'nulos_por_coluna': df_sujo.isna().sum().to_dict(),\n",
    "    'duplicatas_totais': int(df_sujo.duplicated().sum()),\n",
    "}\n",
    "relatorio.update(summary)\n",
    "relatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda373b9",
   "metadata": {},
   "source": [
    "## Salvar CSV com timestamp\n",
    "O arquivo é salvo em `OUTPUT_DIR`, definido acima (Drive ou `/content`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4246f-ba05-400b-adb1-7484f1451543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49a6d2-6ae2-4483-993b-738e1081cf72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9042b4",
   "metadata": {
    "id": "save_csv"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "OUT = os.path.join(OUTPUT_DIR, f\"dataset_sintetico_sujo_8attrs_{ts}.csv\")\n",
    "df_sujo.to_csv(OUT, index=False)\n",
    "print(f\"✅ CSV salvo em: {OUT}\")\n",
    "df_sujo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e835a-a32d-40d4-8270-d0bd04133849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
