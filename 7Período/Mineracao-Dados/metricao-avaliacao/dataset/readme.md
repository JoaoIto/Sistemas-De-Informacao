## üß© **Dados da quest√£o 1**

|                       | Fraude (real) | N√£o fraude (real) |
| --------------------- | ------------- | ----------------- |
| **Previu Fraude**     | 18            | 12                |
| **Previu N√£o fraude** | 2             | 68                |

---

### **a) Matriz de confus√£o (VP, FP, FN, VN)**

| Termo                        | Significado                                   | Valor |
| ---------------------------- | --------------------------------------------- | ----- |
| **VP (Verdadeiro Positivo)** | Fraudes que o modelo detectou corretamente    | 18    |
| **FP (Falso Positivo)**      | Transa√ß√µes normais marcadas como fraude       | 12    |
| **FN (Falso Negativo)**      | Fraudes que o modelo n√£o detectou             | 2     |
| **VN (Verdadeiro Negativo)** | Transa√ß√µes normais identificadas corretamente | 68    |

---

### **b) Quantas previs√µes corretas o modelo fez?**

Corretas = **VP + VN = 18 + 68 = 86**

**O modelo acertou 86 das 100 transa√ß√µes.**

Basicamente o c√°lculo √© feito baseado verdadeiramente no que ele aceitou.

---

## **2. Acur√°cia**

[
\text{Acur√°cia} = \frac{VP + VN}{Total}
]

[
\text{Acur√°cia} = \frac{18 + 68}{100} = \frac{86}{100} = 0.86
]

 **Acur√°cia = 86%**

Mantendo a acur√°cia alta.

---

## **3. Precis√£o (para a classe Fraude)**

[
\text{Precis√£o} = \frac{VP}{VP + FP}
]

[
\text{Precis√£o} = \frac{18}{18 + 12} = \frac{18}{30} = 0.6
]

 **Precis√£o = 60%**

*(Significa que, de todas as vezes que o modelo disse ‚Äúfraude‚Äù, 60% eram realmente fraudes.)*

- Sendo assim mantendo baixa, com a precis√£o que n√£o consegue aceitar com facilidade oque realmente precisa aceitar.

---

## **4. Recall (para a classe Fraude)**

[
\text{Recall} = \frac{VP}{VP + FN}
]

[
\text{Recall} = \frac{18}{18 + 2} = \frac{18}{20} = 0.9
]

**Recall = 90%**

*(Ou seja, o modelo encontrou 90% de todas as fraudes reais.)* 

O que conta com positivos e falsos corretos, com uma boa m√©trica de recall, por tamb√©m 
ter uma boa acur√°cia no modelo

---

## **5. F1-Score**

[
F1 = 2 \times \frac{(Precis√£o \times Recall)}{(Precis√£o + Recall)}
]

[
F1 = 2 \times \frac{(0.6 \times 0.9)}{(0.6 + 0.9)} = 2 \times \frac{0.54}{1.5} = 0.72
]

**F1-score = 0.72 (ou 72%)**

*(Equil√≠brio entre detectar fraudes e evitar falsos alarmes.)*


Um equil√≠brio bem aceit√°vel para isso, mantendo uma boa m√©trica de an√°lise

---

## **6. Interpreta√ß√£o do segundo caso**

> ‚ÄúUm modelo teve **acur√°cia = 95%** e **F1-score = 50%**, e o conjunto est√° **muito desbalanceado**.‚Äù

**Interpreta√ß√£o:**

O modelo acerta quase tudo **porque a maioria das transa√ß√µes √© "n√£o fraude"**, ent√£o ele ‚Äúacerta‚Äù muito apenas por repetir o padr√£o mais comum.
Mas o **F1-score baixo (50%)** mostra que ele **n√£o identifica bem as fraudes** (baixa precis√£o ou recall).

Em resumo:

* O modelo **parece bom pela acur√°cia**, mas **√© fraco para detectar a classe minorit√°ria (fraude)**.
* √â o t√≠pico caso em que a **acur√°cia engana** e m√©tricas como **F1-score** e **Recall** s√£o mais importantes.

---

## **Resumo final**

| M√©trica      | F√≥rmula           | Resultado | Interpreta√ß√£o                                  |
| ------------ | ----------------- | --------- | ---------------------------------------------- |
| **Acur√°cia** | (VP + VN) / Total | 0.86      | 86% dos casos foram classificados corretamente |
| **Precis√£o** | VP / (VP + FP)    | 0.6       | 60% das previs√µes de fraude eram corretas      |
| **Recall**   | VP / (VP + FN)    | 0.9       | 90% das fraudes foram detectadas               |
| **F1-score** | 2 √ó (P√óR)/(P+R)   | 0.72      | Equil√≠brio entre precis√£o e recall             |

---

